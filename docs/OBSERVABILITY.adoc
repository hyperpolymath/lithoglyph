// SPDX-License-Identifier: PMPL-1.0-or-later
= FormDB Observability Guide
:toc: left
:toclevels: 4
:icons: font
:source-highlighter: rouge
:sectanchors:
:sectlinks:

[.lead]
Comprehensive guide to monitoring, logging, tracing, metrics, alerting, backup, and operational visibility for FormDB deployments.

[NOTE]
====
**Status: Documentation Complete, Implementation Planned**

This document provides complete observability guidance. Full observability features are planned for Milestone M10. Currently, basic logging and journal introspection are available.
====

== Observability Philosophy

FormDB's audit-first design provides unique observability advantages:

[cols="1,2,2"]
|===
| Traditional DB | FormDB | Advantage

| Audit tables optional
| Journal built-in
| Complete operation history by default

| "Who changed this?" = detective work
| Provenance on every mutation
| Actor + rationale always available

| Schema history = migration files
| Self-normalizing with proofs
| Schema evolution is queryable

| Metrics = external instrumentation
| Introspection is native
| Query the database about itself
|===

=== Three Pillars of Observability

[cols="1,3"]
|===
| Pillar | FormDB Implementation

| **Logs**
| Structured JSON logs with operation context, provenance, and timing

| **Metrics**
| Prometheus-compatible metrics for queries, journal, storage, and constraints

| **Traces**
| OpenTelemetry spans for distributed request tracing
|===

=== Built-In Observability

FormDB provides observability features that other databases require external tools for:

[source,fql]
----
-- Query audit history (built-in)
SELECT * FROM _journal
WHERE collection = 'evidence'
  AND provenance.actor = 'alice'
ORDER BY sequence DESC
LIMIT 100;

-- Schema evolution history (built-in)
SELECT * FROM _schema_history
WHERE collection = 'evidence'
ORDER BY version DESC;

-- Constraint violation history (built-in)
SELECT * FROM _constraint_violations
WHERE occurred_at > NOW() - INTERVAL '1 hour';
----

== Logging

=== Log Levels

[cols="1,1,3"]
|===
| Level | Numeric | Description

| `FATAL`
| 0
| Unrecoverable errors requiring immediate shutdown

| `ERROR`
| 1
| Recoverable errors, constraint violations, failed operations

| `WARN`
| 2
| Deprecation warnings, performance concerns, unusual conditions

| `INFO`
| 3
| Operations, lifecycle events, configuration changes

| `DEBUG`
| 4
| Detailed internal state, query plans, decision points

| `TRACE`
| 5
| Very verbose, individual block operations (development only)
|===

=== Log Format

FormDB uses structured JSON logging for machine-parseable output:

.Standard Log Entry
[source,json]
----
{
  "timestamp": "2026-01-12T10:30:45.123456Z",
  "level": "INFO",
  "component": "Form.Runtime",
  "node_id": "fdb-prod-01",
  "request_id": "req_abc123def456",
  "trace_id": "4bf92f3577b34da6a3ce929d0e0e4736",
  "span_id": "00f067aa0ba902b7",
  "message": "Query executed successfully",
  "operation": "SELECT",
  "collection": "evidence",
  "documents_returned": 42,
  "duration_ms": 12.5,
  "actor": "user:alice@session:xyz",
  "client_ip": "192.168.1.100"
}
----

.Error Log Entry
[source,json]
----
{
  "timestamp": "2026-01-12T10:31:00.000000Z",
  "level": "ERROR",
  "component": "Form.Constraints",
  "node_id": "fdb-prod-01",
  "request_id": "req_def789ghi012",
  "message": "Constraint violation",
  "operation": "INSERT",
  "collection": "evidence",
  "constraint": "score_range",
  "constraint_type": "CHECK",
  "violation_details": {
    "field": "score",
    "value": 150,
    "expected": "0 <= score <= 100"
  },
  "actor": "user:bob@session:abc",
  "error_code": "CONSTRAINT_VIOLATION",
  "error_id": 1003
}
----

.Journal Operation Log
[source,json]
----
{
  "timestamp": "2026-01-12T10:32:15.789012Z",
  "level": "INFO",
  "component": "Form.Journal",
  "node_id": "fdb-prod-01",
  "message": "Journal entry written",
  "sequence": 100542,
  "operation": "UPDATE",
  "collection": "evidence",
  "document_key": "doc_12345",
  "previous_sequence": 100541,
  "block_id": 2048,
  "provenance": {
    "actor": "user:carol@session:mno",
    "rationale": "Correcting source attribution per editor review"
  },
  "has_inverse": true
}
----

=== Log Configuration

.Configuration File (formdb.toml)
[source,toml]
----
[logging]
# Log level: fatal, error, warn, info, debug, trace
level = "info"

# Output format: json, text, pretty
format = "json"

# Output destination: stdout, stderr, file, syslog
output = "stdout"

# File output settings (when output = "file")
[logging.file]
path = "/var/log/formdb/formdb.log"
max_size_mb = 100
max_files = 10
compress = true

# Syslog settings (when output = "syslog")
[logging.syslog]
facility = "local0"
tag = "formdb"

# Component-specific log levels
[logging.components]
"Form.Runtime" = "info"
"Form.Journal" = "info"
"Form.Blocks" = "warn"
"Form.Constraints" = "debug"  # More detail for constraint debugging
"Form.HTTP" = "info"
"Form.gRPC" = "info"

# Sensitive data filtering
[logging.filter]
# Fields to redact from logs
redact_fields = ["password", "api_key", "token", "secret"]
# Truncate long values
max_value_length = 1000
----

=== Log Destinations

[cols="1,2,2"]
|===
| Destination | Use Case | Configuration

| **stdout/stderr**
| Container deployments (Docker, K8s)
| `output = "stdout"`

| **File**
| Traditional server deployments
| `output = "file"` with rotation

| **Syslog**
| Enterprise log aggregation
| `output = "syslog"` with facility

| **Journald**
| systemd-based Linux systems
| `output = "journald"`
|===

=== Log Aggregation Integration

==== Fluentd Configuration

[source,yaml]
----
# fluentd/formdb.conf
<source>
  @type tail
  path /var/log/formdb/formdb.log
  pos_file /var/log/fluentd/formdb.pos
  tag formdb
  <parse>
    @type json
    time_key timestamp
    time_format %Y-%m-%dT%H:%M:%S.%NZ
  </parse>
</source>

<filter formdb>
  @type record_transformer
  <record>
    environment production
    service formdb
  </record>
</filter>

<match formdb>
  @type elasticsearch
  host elasticsearch.logging.svc.cluster.local
  port 9200
  index_name formdb-logs
  type_name _doc
</match>
----

==== Vector Configuration

[source,toml]
----
# vector/formdb.toml
[sources.formdb_logs]
type = "file"
include = ["/var/log/formdb/*.log"]
read_from = "beginning"

[transforms.formdb_parse]
type = "remap"
inputs = ["formdb_logs"]
source = '''
. = parse_json!(.message)
.environment = "production"
'''

[sinks.loki]
type = "loki"
inputs = ["formdb_parse"]
endpoint = "http://loki:3100"
labels.service = "formdb"
labels.component = "{{ component }}"
labels.level = "{{ level }}"

[sinks.datadog]
type = "datadog_logs"
inputs = ["formdb_parse"]
default_api_key = "${DATADOG_API_KEY}"
----

==== Loki Labels

[source,yaml]
----
# Recommended Loki labels for FormDB logs
labels:
  - service: formdb
  - environment: production
  - node_id: fdb-prod-01
  - component: Form.Runtime
  - level: info
  - operation: SELECT
  - collection: evidence
----

== Metrics

=== Prometheus Metrics

FormDB exports Prometheus-compatible metrics on the `/metrics` endpoint.

==== Query Metrics

[cols="1,1,3"]
|===
| Metric | Type | Description

| `formdb_queries_total`
| Counter
| Total queries executed, labeled by operation and collection

| `formdb_query_duration_seconds`
| Histogram
| Query execution time distribution

| `formdb_query_rows_returned`
| Histogram
| Number of documents returned per query

| `formdb_query_errors_total`
| Counter
| Query errors by error type

| `formdb_query_in_flight`
| Gauge
| Currently executing queries
|===

[source,prometheus]
----
# HELP formdb_queries_total Total number of queries executed
# TYPE formdb_queries_total counter
formdb_queries_total{operation="SELECT",collection="evidence",status="success"} 15234
formdb_queries_total{operation="INSERT",collection="evidence",status="success"} 1234
formdb_queries_total{operation="INSERT",collection="evidence",status="error"} 12

# HELP formdb_query_duration_seconds Query execution time
# TYPE formdb_query_duration_seconds histogram
formdb_query_duration_seconds_bucket{operation="SELECT",le="0.001"} 1000
formdb_query_duration_seconds_bucket{operation="SELECT",le="0.01"} 5000
formdb_query_duration_seconds_bucket{operation="SELECT",le="0.1"} 10000
formdb_query_duration_seconds_bucket{operation="SELECT",le="1"} 15000
formdb_query_duration_seconds_bucket{operation="SELECT",le="+Inf"} 15234
formdb_query_duration_seconds_sum{operation="SELECT"} 152.34
formdb_query_duration_seconds_count{operation="SELECT"} 15234
----

==== Journal Metrics

[cols="1,1,3"]
|===
| Metric | Type | Description

| `formdb_journal_entries_total`
| Counter
| Total journal entries written

| `formdb_journal_sequence`
| Gauge
| Current journal sequence number

| `formdb_journal_write_duration_seconds`
| Histogram
| Journal write latency

| `formdb_journal_replay_entries`
| Counter
| Entries replayed during recovery

| `formdb_journal_size_bytes`
| Gauge
| Total journal size on disk
|===

==== Storage Metrics

[cols="1,1,3"]
|===
| Metric | Type | Description

| `formdb_storage_bytes_total`
| Gauge
| Total storage used

| `formdb_storage_blocks_total`
| Gauge
| Total blocks allocated

| `formdb_storage_blocks_free`
| Gauge
| Free blocks available

| `formdb_storage_collections`
| Gauge
| Number of collections

| `formdb_storage_documents_total`
| Gauge
| Total documents across all collections

| `formdb_storage_edges_total`
| Gauge
| Total edges across all edge collections
|===

==== Constraint Metrics

[cols="1,1,3"]
|===
| Metric | Type | Description

| `formdb_constraint_checks_total`
| Counter
| Total constraint evaluations

| `formdb_constraint_violations_total`
| Counter
| Constraint violation count by constraint name

| `formdb_constraint_check_duration_seconds`
| Histogram
| Constraint evaluation time
|===

==== Connection Metrics

[cols="1,1,3"]
|===
| Metric | Type | Description

| `formdb_connections_total`
| Counter
| Total connections opened

| `formdb_connections_active`
| Gauge
| Currently active connections

| `formdb_connections_idle`
| Gauge
| Idle connections in pool

| `formdb_connection_errors_total`
| Counter
| Connection errors by type
|===

=== Prometheus Configuration

[source,yaml]
----
# prometheus/prometheus.yml
scrape_configs:
  - job_name: 'formdb'
    scrape_interval: 15s
    static_configs:
      - targets:
          - 'formdb-prod-01:9090'
          - 'formdb-prod-02:9090'
          - 'formdb-prod-03:9090'
    relabel_configs:
      - source_labels: [__address__]
        target_label: instance
        regex: '([^:]+):\d+'
        replacement: '${1}'
    metric_relabel_configs:
      - source_labels: [__name__]
        regex: 'formdb_.*'
        action: keep
----

=== Alert Rules

[source,yaml]
----
# prometheus/alerts/formdb.yml
groups:
  - name: formdb
    rules:
      # High query latency
      - alert: FormDBHighQueryLatency
        expr: |
          histogram_quantile(0.99, sum(rate(formdb_query_duration_seconds_bucket[5m])) by (le)) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High query latency detected"
          description: "99th percentile query latency is {{ $value }}s"

      # High error rate
      - alert: FormDBHighErrorRate
        expr: |
          sum(rate(formdb_query_errors_total[5m])) /
          sum(rate(formdb_queries_total[5m])) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High query error rate"
          description: "Error rate is {{ $value | humanizePercentage }}"

      # Journal write failures
      - alert: FormDBJournalWriteFailures
        expr: |
          increase(formdb_journal_write_errors_total[5m]) > 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Journal write failures detected"
          description: "{{ $value }} journal write failures in last 5 minutes"

      # Storage space low
      - alert: FormDBStorageSpaceLow
        expr: |
          (formdb_storage_blocks_free / formdb_storage_blocks_total) < 0.1
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "Low storage space"
          description: "Only {{ $value | humanizePercentage }} storage remaining"

      # Connection pool exhaustion
      - alert: FormDBConnectionPoolExhausted
        expr: |
          formdb_connections_active / formdb_connections_max > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Connection pool near exhaustion"
          description: "{{ $value | humanizePercentage }} of connections in use"

      # Constraint violations spike
      - alert: FormDBConstraintViolationSpike
        expr: |
          increase(formdb_constraint_violations_total[5m]) > 100
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High constraint violation rate"
          description: "{{ $value }} constraint violations in 5 minutes"

      # Node down
      - alert: FormDBNodeDown
        expr: up{job="formdb"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "FormDB node is down"
          description: "Node {{ $labels.instance }} is not responding"
----

=== Grafana Dashboards

==== Overview Dashboard

[source,json]
----
{
  "title": "FormDB Overview",
  "panels": [
    {
      "title": "Query Rate",
      "type": "graph",
      "targets": [
        {
          "expr": "sum(rate(formdb_queries_total[1m])) by (operation)",
          "legendFormat": "{{operation}}"
        }
      ]
    },
    {
      "title": "Query Latency (p99)",
      "type": "graph",
      "targets": [
        {
          "expr": "histogram_quantile(0.99, sum(rate(formdb_query_duration_seconds_bucket[5m])) by (le, operation))",
          "legendFormat": "{{operation}}"
        }
      ]
    },
    {
      "title": "Error Rate",
      "type": "singlestat",
      "targets": [
        {
          "expr": "sum(rate(formdb_query_errors_total[5m])) / sum(rate(formdb_queries_total[5m]))"
        }
      ],
      "format": "percentunit"
    },
    {
      "title": "Active Connections",
      "type": "gauge",
      "targets": [
        {
          "expr": "sum(formdb_connections_active)"
        }
      ]
    },
    {
      "title": "Journal Sequence",
      "type": "singlestat",
      "targets": [
        {
          "expr": "formdb_journal_sequence"
        }
      ]
    },
    {
      "title": "Storage Used",
      "type": "gauge",
      "targets": [
        {
          "expr": "sum(formdb_storage_bytes_total)"
        }
      ],
      "format": "bytes"
    }
  ]
}
----

==== Performance Dashboard Panels

[source]
----
Query Performance:
├── Query Rate by Operation (graph)
├── Query Latency Percentiles (graph: p50, p90, p99)
├── Slow Queries (table: queries > 100ms)
├── Query Errors by Type (graph)
└── Cache Hit Rate (gauge)

Journal Performance:
├── Journal Write Rate (graph)
├── Journal Write Latency (graph)
├── Journal Size Growth (graph)
├── Sequence Number (counter)
└── Replay Progress (during recovery)

Storage Performance:
├── Block Operations (graph: reads, writes)
├── Block I/O Latency (graph)
├── Storage Utilization (gauge)
├── Free Blocks Trend (graph)
└── Compaction Activity (graph)

Constraint Performance:
├── Constraint Checks per Second (graph)
├── Constraint Check Latency (graph)
├── Violations by Constraint (bar chart)
└── Constraint Evaluation Cache Hit Rate (gauge)
----

== Tracing

=== OpenTelemetry Integration

FormDB supports OpenTelemetry for distributed tracing.

==== Configuration

[source,toml]
----
[tracing]
# Enable/disable tracing
enabled = true

# Sampling rate (0.0 to 1.0)
sample_rate = 0.1

# Exporter: otlp, jaeger, zipkin
exporter = "otlp"

# OTLP endpoint
[tracing.otlp]
endpoint = "http://otel-collector:4317"
protocol = "grpc"  # or "http"

# Jaeger endpoint (if exporter = "jaeger")
[tracing.jaeger]
endpoint = "http://jaeger:14268/api/traces"

# Resource attributes
[tracing.resource]
service.name = "formdb"
service.version = "0.0.2"
deployment.environment = "production"
----

==== Span Structure

[source]
----
Trace: formdb.query
├── formdb.query.parse        (1ms)
│   └── Parse FQL query string
├── formdb.query.plan         (2ms)
│   └── Generate query execution plan
├── formdb.query.validate     (1ms)
│   └── Validate query against schema
├── formdb.query.execute      (50ms)
│   ├── formdb.storage.read   (45ms)
│   │   ├── formdb.block.read (10ms)
│   │   ├── formdb.block.read (10ms)
│   │   └── formdb.block.read (10ms)
│   └── formdb.filter         (5ms)
└── formdb.serialize          (2ms)
    └── Convert results to JSON
----

==== Trace Attributes

[cols="1,2"]
|===
| Attribute | Description

| `db.system`
| Always "formdb"

| `db.operation`
| FQL operation (SELECT, INSERT, UPDATE, DELETE)

| `db.collection`
| Target collection name

| `db.statement`
| Sanitized FQL query (parameters removed)

| `formdb.sequence`
| Journal sequence number (for mutations)

| `formdb.actor`
| Provenance actor

| `formdb.documents_affected`
| Number of documents affected

| `formdb.constraint_checks`
| Number of constraints evaluated
|===

==== Context Propagation

[source,rust]
----
// Rust client example
use opentelemetry::trace::{Tracer, TraceContextExt};
use formdb::Client;

async fn query_with_tracing(client: &Client, query: &str) -> Result<Vec<Document>> {
    let tracer = global::tracer("my-application");

    tracer.in_span("my_operation", |cx| async {
        // Trace context is automatically propagated
        let result = client.query(query).await?;

        // Add custom attributes
        cx.span().set_attribute(KeyValue::new("app.query_purpose", "user_lookup"));

        Ok(result)
    }).await
}
----

=== Jaeger UI Queries

[source]
----
# Find slow queries
service=formdb operation=formdb.query.execute minDuration=100ms

# Find failed operations
service=formdb error=true

# Find queries for specific collection
service=formdb db.collection=evidence

# Find queries by actor
service=formdb formdb.actor=user:alice
----

== Health Checks

=== Endpoints

[cols="1,2,2"]
|===
| Endpoint | Purpose | Response

| `GET /health`
| Basic liveness
| `200 OK` if process is running

| `GET /health/ready`
| Readiness to serve traffic
| `200 OK` if can accept queries

| `GET /health/live`
| Kubernetes liveness probe
| `200 OK` if not deadlocked

| `GET /health/startup`
| Kubernetes startup probe
| `200 OK` after initialization
|===

=== Detailed Health Response

[source,json]
----
{
  "status": "healthy",
  "timestamp": "2026-01-12T10:30:00Z",
  "version": "0.0.2",
  "uptime_seconds": 86400,
  "components": {
    "journal": {
      "status": "healthy",
      "sequence": 100542,
      "last_write": "2026-01-12T10:29:55Z",
      "write_latency_ms": 2.5
    },
    "storage": {
      "status": "healthy",
      "blocks_total": 100000,
      "blocks_free": 45000,
      "utilization": 0.55
    },
    "connections": {
      "status": "healthy",
      "active": 25,
      "idle": 75,
      "max": 200
    },
    "memory": {
      "status": "healthy",
      "heap_used_bytes": 536870912,
      "heap_total_bytes": 1073741824,
      "gc_pause_ms": 1.2
    }
  },
  "checks": {
    "journal_writable": true,
    "storage_writable": true,
    "can_accept_queries": true
  }
}
----

=== Kubernetes Probes

[source,yaml]
----
# kubernetes/formdb-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: formdb
spec:
  template:
    spec:
      containers:
        - name: formdb
          image: formdb:0.0.2
          ports:
            - containerPort: 8765
              name: fql
            - containerPort: 9090
              name: metrics
          livenessProbe:
            httpGet:
              path: /health/live
              port: 9090
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /health/ready
              port: 9090
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 3
            failureThreshold: 3
          startupProbe:
            httpGet:
              path: /health/startup
              port: 9090
            initialDelaySeconds: 0
            periodSeconds: 5
            timeoutSeconds: 5
            failureThreshold: 30
----

== Backup & Restore

=== Backup Strategy

FormDB's append-only journal enables powerful backup capabilities:

[cols="1,3"]
|===
| Strategy | Description

| **Full Backup**
| Complete database snapshot including journal, blocks, and metadata

| **Incremental Backup**
| Only journal entries since last backup (extremely efficient)

| **Continuous Archival**
| Stream journal to object storage in real-time

| **Point-in-Time Recovery**
| Restore to any journal sequence number
|===

=== Backup Commands

[source,bash]
----
# Full backup to local directory
formdb backup \
    --type full \
    --source /var/lib/formdb/data \
    --destination /backup/formdb-full-$(date +%Y%m%d)

# Full backup to S3
formdb backup \
    --type full \
    --source /var/lib/formdb/data \
    --destination s3://my-bucket/formdb/full-$(date +%Y%m%d)

# Incremental backup (since last full backup)
formdb backup \
    --type incremental \
    --source /var/lib/formdb/data \
    --since-sequence 100000 \
    --destination s3://my-bucket/formdb/incr-$(date +%Y%m%d%H%M)

# Continuous backup (streaming)
formdb backup \
    --type continuous \
    --source /var/lib/formdb/data \
    --destination s3://my-bucket/formdb/journal/ \
    --daemon
----

=== Backup Configuration

[source,toml]
----
[backup]
# Enable automatic backups
enabled = true

# Backup schedule
[backup.schedule]
# Full backup: weekly on Sunday at 2 AM
full = "0 2 * * 0"
# Incremental: hourly
incremental = "0 * * * *"

# Backup destinations
[backup.destinations.primary]
type = "s3"
bucket = "formdb-backups"
prefix = "production/"
region = "us-east-1"
storage_class = "STANDARD_IA"

[backup.destinations.secondary]
type = "gcs"
bucket = "formdb-backups-dr"
prefix = "production/"
region = "us-central1"

# Retention policy
[backup.retention]
full_backups_keep = 4      # Keep 4 weekly full backups
incremental_keep_days = 7  # Keep 7 days of incrementals
journal_archive_days = 90  # Archive journal for 90 days

# Encryption
[backup.encryption]
enabled = true
key_source = "kms"
kms_key_id = "alias/formdb-backup-key"
----

=== Restore Procedures

[source,bash]
----
# Restore from full backup
formdb restore \
    --source s3://my-bucket/formdb/full-20260112 \
    --destination /var/lib/formdb/data \
    --verify

# Restore to specific point in time
formdb restore \
    --source s3://my-bucket/formdb/full-20260105 \
    --destination /var/lib/formdb/data \
    --apply-incremental s3://my-bucket/formdb/incr-* \
    --to-sequence 105000

# Restore to timestamp
formdb restore \
    --source s3://my-bucket/formdb/full-20260105 \
    --destination /var/lib/formdb/data \
    --apply-incremental s3://my-bucket/formdb/incr-* \
    --to-timestamp "2026-01-10T14:30:00Z"

# Verify backup integrity
formdb backup verify \
    --source s3://my-bucket/formdb/full-20260112 \
    --checksum

# List available restore points
formdb restore list \
    --source s3://my-bucket/formdb/ \
    --from 2026-01-01 \
    --to 2026-01-12
----

=== Backup Verification

[source,bash]
----
# Verify backup integrity without restore
formdb backup verify \
    --source s3://my-bucket/formdb/full-20260112 \
    --deep  # Verify all blocks and checksums

# Test restore to temporary location
formdb restore \
    --source s3://my-bucket/formdb/full-20260112 \
    --destination /tmp/formdb-test \
    --verify \
    --readonly

# Compare backup with live database
formdb backup compare \
    --backup s3://my-bucket/formdb/full-20260112 \
    --live /var/lib/formdb/data \
    --report /tmp/compare-report.json
----

== Disaster Recovery

=== Recovery Objectives

[cols="1,2,2"]
|===
| Objective | Target | Implementation

| **RPO** (Recovery Point Objective)
| < 1 hour
| Hourly incremental backups + continuous journal archival

| **RTO** (Recovery Time Objective)
| < 4 hours
| Automated restore procedures + standby instances

| **Data Integrity**
| Zero data loss for committed transactions
| Journal durability + backup verification
|===

=== DR Architecture

[source]
----
Primary Region (us-east-1)
├── FormDB Primary (active)
│   ├── Journal → S3 (continuous backup)
│   └── Metrics → CloudWatch
├── FormDB Replica (standby)
└── Backup Storage (S3)
    ├── Full backups (weekly)
    └── Incremental (hourly)

DR Region (us-west-2)
├── FormDB Standby (cold standby)
├── Backup Storage (S3, replicated)
└── DNS Failover (Route 53)
----

=== Failover Procedures

.Automated Failover
[source,yaml]
----
# Runbook: Automated Failover
---
name: FormDB Automated Failover
trigger:
  - health_check_failed for 5m
  - manual_trigger

steps:
  - name: Verify primary is truly down
    command: formdb health --target primary --timeout 30s
    expect: failure

  - name: Stop writes to primary
    command: formdb drain --target primary
    timeout: 60s

  - name: Promote replica to primary
    command: formdb promote --target replica
    verify: formdb health --target replica

  - name: Update DNS
    command: |
      aws route53 change-resource-record-sets \
        --hosted-zone-id $ZONE_ID \
        --change-batch file://failover-dns.json

  - name: Verify new primary
    command: formdb verify --target new-primary
    expect: success

  - name: Notify on-call
    command: pagerduty trigger --severity critical --message "FormDB failover completed"
----

.Manual Recovery from Backup
[source,bash]
----
#!/bin/bash
# manual-recovery.sh - Manual FormDB recovery procedure

set -euo pipefail

BACKUP_SOURCE="s3://formdb-backups/production/full-latest"
RESTORE_TARGET="/var/lib/formdb/data"
TIMESTAMP="${1:-now}"

echo "=== FormDB Manual Recovery ==="
echo "Backup Source: $BACKUP_SOURCE"
echo "Target: $RESTORE_TARGET"
echo "Timestamp: $TIMESTAMP"

# 1. Stop FormDB if running
echo "Stopping FormDB..."
systemctl stop formdb || true

# 2. Backup current state (if any)
if [ -d "$RESTORE_TARGET" ]; then
    echo "Backing up current state..."
    mv "$RESTORE_TARGET" "${RESTORE_TARGET}.pre-recovery-$(date +%s)"
fi

# 3. Restore from backup
echo "Restoring from backup..."
formdb restore \
    --source "$BACKUP_SOURCE" \
    --destination "$RESTORE_TARGET" \
    --to-timestamp "$TIMESTAMP" \
    --verify

# 4. Verify restore
echo "Verifying restore..."
formdb verify --data-dir "$RESTORE_TARGET"

# 5. Start FormDB
echo "Starting FormDB..."
systemctl start formdb

# 6. Health check
echo "Running health check..."
sleep 10
formdb health --wait 60s

echo "=== Recovery Complete ==="
formdb status
----

=== DR Testing

[source,toml]
----
# DR test schedule (quarterly)
[dr_test]
schedule = "0 2 1 */3 *"  # First day of each quarter at 2 AM

[dr_test.scenarios]
# Test 1: Backup/Restore
backup_restore = """
1. Create test data in isolated namespace
2. Perform full backup
3. Delete test data
4. Restore from backup
5. Verify data integrity
"""

# Test 2: Failover
failover = """
1. Simulate primary failure
2. Trigger automated failover
3. Verify replica becomes primary
4. Verify no data loss
5. Restore primary and fail back
"""

# Test 3: Point-in-Time Recovery
pitr = """
1. Create test data with known timestamp
2. Perform backup
3. Create more data
4. Restore to earlier timestamp
5. Verify only pre-timestamp data exists
"""
----

== Operational Runbooks

=== Common Operations

==== Investigating Slow Queries

[source,fql]
----
-- 1. Check current slow queries
SELECT * FROM _slow_query_log
WHERE duration_ms > 100
  AND occurred_at > NOW() - INTERVAL '1 hour'
ORDER BY duration_ms DESC
LIMIT 20;

-- 2. Analyze query plan
EXPLAIN ANALYZE
SELECT * FROM evidence
WHERE source = 'leaked-document'
  AND score > 80;

-- 3. Check index usage
INTROSPECT COLLECTION evidence;

-- 4. Review constraint overhead
SELECT * FROM _constraint_timing
WHERE collection = 'evidence'
  AND check_duration_ms > 10;
----

==== Recovering from Constraint Violation Spike

[source,bash]
----
#!/bin/bash
# runbook: constraint-violation-spike.sh

# 1. Identify which constraints are failing
formdb query "
  SELECT constraint_name, COUNT(*) as violations
  FROM _constraint_violations
  WHERE occurred_at > NOW() - INTERVAL '30 minutes'
  GROUP BY constraint_name
  ORDER BY violations DESC
"

# 2. Get sample violations
formdb query "
  SELECT *
  FROM _constraint_violations
  WHERE constraint_name = '\$CONSTRAINT_NAME'
  LIMIT 10
"

# 3. Identify actor patterns
formdb query "
  SELECT actor, COUNT(*) as violations
  FROM _constraint_violations
  WHERE occurred_at > NOW() - INTERVAL '30 minutes'
  GROUP BY actor
  ORDER BY violations DESC
"

# 4. If caused by bad data, consider temporary constraint relaxation
# formdb alter collection evidence DROP CONSTRAINT score_range;
# ... fix data ...
# formdb alter collection evidence ADD CONSTRAINT score_range CHECK (score >= 0 AND score <= 100);
----

==== Journal Compaction

[source,bash]
----
#!/bin/bash
# runbook: journal-compaction.sh

# 1. Check journal size
formdb journal stats

# 2. Estimate compaction impact
formdb journal compact --dry-run --since 30d

# 3. Perform compaction (during low-traffic window)
formdb journal compact \
    --since 30d \
    --archive s3://formdb-archive/journal/ \
    --verify

# 4. Verify journal health after compaction
formdb journal verify
----

==== Recovering from Corruption

[source,bash]
----
#!/bin/bash
# runbook: corruption-recovery.sh

# 1. Stop FormDB
systemctl stop formdb

# 2. Run integrity check
formdb verify --data-dir /var/lib/formdb/data --deep

# 3. If corruption found, identify affected blocks
formdb verify --data-dir /var/lib/formdb/data --report /tmp/corruption-report.json

# 4. Attempt repair from journal
formdb repair \
    --data-dir /var/lib/formdb/data \
    --replay-journal \
    --verify

# 5. If repair fails, restore from backup
formdb restore \
    --source s3://formdb-backups/latest \
    --destination /var/lib/formdb/data.restored \
    --verify

# 6. Swap directories and restart
mv /var/lib/formdb/data /var/lib/formdb/data.corrupted
mv /var/lib/formdb/data.restored /var/lib/formdb/data
systemctl start formdb
----

=== Capacity Planning

[source,fql]
----
-- Storage growth analysis
SELECT
    date_trunc('day', created_at) as day,
    COUNT(*) as documents_added,
    SUM(document_size_bytes) as bytes_added
FROM _storage_audit
WHERE created_at > NOW() - INTERVAL '30 days'
GROUP BY day
ORDER BY day;

-- Project storage needs
SELECT
    current_size_gb,
    daily_growth_gb,
    current_size_gb + (daily_growth_gb * 90) as size_in_90_days,
    current_size_gb + (daily_growth_gb * 365) as size_in_1_year
FROM (
    SELECT
        SUM(size_bytes) / 1e9 as current_size_gb,
        AVG(daily_growth_bytes) / 1e9 as daily_growth_gb
    FROM _storage_summary
);

-- Query load projection
SELECT
    date_trunc('day', timestamp) as day,
    COUNT(*) as queries,
    AVG(duration_ms) as avg_latency
FROM _query_log
WHERE timestamp > NOW() - INTERVAL '30 days'
GROUP BY day
ORDER BY day;
----

== See Also

* link:DEPLOYMENT.adoc[Deployment Guide] - Production deployment
* link:SECURITY-AUTH.adoc[Security & Authentication] - Security hardening
* link:API-REFERENCE.adoc[API Reference] - Programmatic interfaces
* link:../ARCHITECTURE.adoc[Architecture] - Technical design
* link:../spec/journal.adoc[Journal Specification] - Journal format details
